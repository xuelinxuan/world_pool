
name: CD

permissions:
  id-token: write
  contents: read

# on:
#   workflow_run:
#     workflows: ["CI"]   # å¿…é¡»å’Œ CI workflow çš„ name å®Œå…¨ä¸€è‡´
#     types: [completed]
#     branches: [main]       # åªæœ‰ main ä¸Šçš„ CI å®Œæˆæ‰è§¦å‘

on:
  workflow_dispatch:
  push:
    branches: [main]

jobs:
  deploy:
    name: II.CD run_code
    # if: ${{ github.event.workflow_run.conclusion == 'success' }}  # ä»…å½“ CI æˆåŠŸ
    runs-on: ubuntu-latest
    steps:
    - name: 0.Check out Git repository
      uses: actions/checkout@v4

    - name: 1.Configure aws credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region:            ${{ secrets.AWS_REGION }}



    - name: 2.Start EC2 instance
      run: |
        aws ec2 start-instances         --instance-ids ${{ secrets.EC2_INSTANCE_ID }}
        #ç¡®è®¤è¿æ¥æˆåŠŸ
        aws ec2 wait instance-status-ok --instance-ids ${{ secrets.EC2_INSTANCE_ID }}
        echo "âœ… EC2 instance is running"

    - name: 3.Deploy DAGs to EC2 (SCP)
      uses: appleboy/scp-action@v0.1.7
      with:
        host    : ${{ secrets.SSH_HOST }}
        username: ${{ secrets.SSH_USER }}
        key     : ${{ secrets.SSH_KEY }}        # éƒ¨ç½²ä¸“ç”¨ç§é’¥
        source  : dags/
        target  : /home/ubuntu/world_pool/dags/


    - name: 3.Setup Airflow via SSM
      env:
        DAGS_BRANCH: main 
      run: |
        set -euo pipefail

        DAGS_BRANCH="${DAGS_BRANCH:-main}"
    
        jq -n --arg BR "${DAGS_BRANCH}" '{
          commands: [
            "set -eu",
            "export HOME=/root",
            
            # é¿å… root ä¸‹ git dubious ownership
            "git config --global --add safe.directory /home/ubuntu/world_pool || true",
            "git config --global --add safe.directory /home/ubuntu/world_pool/dags || true",
            "cd /home/ubuntu/world_pool/dags",
            # æ‹‰æœ€æ–°ä»£ç ï¼ˆç”¨ --ff-only é˜²æ­¢äº§ç”Ÿåˆå¹¶æäº¤ï¼›ä½ ä¹Ÿå¯æ”¹æˆ fetch/resetï¼‰
            "git fetch --all --prune",
            "git checkout --quiet " + $BR + " || true",
            "git pull --ff-only origin " + $BR,
    
            # å›åˆ° compose ç›®å½•å¹¶å¯åŠ¨/åˆ·æ–°å®¹å™¨
            "cd /home/ubuntu/world_pool",
            "sudo systemctl start docker || true",
            "sudo docker compose up -d --remove-orphans",
            "sudo docker compose ps"
            ]
          }' > params.json

        # jq -n --arg s "$SCRIPT" '{commands: [$s]}' > params.json

        CMD_ID=$(aws ssm send-command \
          --targets "Key=instanceIds,Values=${{ secrets.EC2_INSTANCE_ID }}" \
          --document-name "AWS-RunShellScript" \
          --comment "Start/Update Airflow (compose v2)" \
          --region "${{ secrets.AWS_REGION }}" \
          --parameters file://params.json \
          --query "Command.CommandId" --output text)
          
        echo "SSM Command ID: $CMD_ID"

        # 1) ç­‰å¾…è¿œç«¯æ‰§è¡Œç»“æŸï¼ˆå³ä½¿å¤±è´¥ä¹Ÿå…ˆåˆ«ä¸­æ–­ï¼‰
        set +e
        aws ssm wait command-executed \
          --command-id "$CMD_ID" \
          --instance-id "${{ secrets.EC2_INSTANCE_ID }}" \
          --region "${{ secrets.AWS_REGION }}"
        STATUS=$?     # 0=Successï¼Œé0=Failed/TimedOut/Canceled
        set -e        # 2) ç«‹åˆ»æ¢å¤â€œé‡é”™å³åœâ€
        
        # 3) æ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½æŠŠè¿œç«¯æ—¥å¿—å–å›æ¥ä¾¿äºæ’æŸ¥
        aws ssm get-command-invocation \
          --command-id "$CMD_ID" \
          --instance-id "${{ secrets.EC2_INSTANCE_ID }}" \
          --region "${{ secrets.AWS_REGION }}" \
          --query '{Status:Status, StdOut:StandardOutputContent, StdErr:StandardErrorContent}' \
          --output json
        
        # 4) ç”¨è¿œç«¯æ‰§è¡Œç»“æœä½œä¸ºå½“å‰ step çš„é€€å‡ºç 
        exit $STATUS
          
    - name: 4.Run Airflow dag
      env:
        AIRFLOW_HOST: ${{ secrets.AIRFLOW_HOST }}
        AIRFLOW_USER: ${{ secrets.AIRFLOW_USER }}
        AIRFLOW_PASS: ${{ secrets.AIRFLOW_PASS }}
        DAG_ID      : market_history
      run: |
        set -euo pipefail
    
        # 1) ç”Ÿæˆæœ¬æ¬¡è¿è¡Œçš„ dag_run_idï¼ˆè‡ªå·±å¯æ§ï¼Œæ— éœ€ URL ç¼–ç ï¼‰
        DAG_RUN_ID="manual__$(date -u +%s)"
        echo "Triggering DAG: ${DAG_ID} with DAG_RUN_ID=${DAG_RUN_ID}"
    
        # 2) è§¦å‘ DAG
        curl -fSs -X POST "http://${AIRFLOW_HOST}:8080/api/v1/dags/${DAG_ID}/dagRuns" \
          -H "Content-Type: application/json" \
          -u "${AIRFLOW_USER}:${AIRFLOW_PASS}" \
          -d "{\"dag_run_id\": \"${DAG_RUN_ID}\", \"conf\": {\"key\": \"value\"}}"
    
        # 3) è½®è¯¢çŠ¶æ€ï¼ˆæ¯ 50 ç§’æŸ¥ä¸€æ¬¡ï¼Œæœ€å¤š 30 æ¬¡ â‰ˆ 25 åˆ†é’Ÿï¼‰
        for i in {1..30}; do
          STATE=$(curl -fsS -u "${AIRFLOW_USER}:${AIRFLOW_PASS}" \
            "http://${AIRFLOW_HOST}:8080/api/v1/dags/${DAG_ID}/dagRuns/${DAG_RUN_ID}" | jq -r '.state')
    
          echo "[$i] DAG run state: ${STATE:-<no state>}"
          if [[ "$STATE" == "success" ]]; then
            echo "âœ… DAG succeeded"
            exit 0
          elif [[ "$STATE" == "failed" ]]; then
            echo "âŒ DAG failed"
            exit 1
          fi
          sleep 10
        done
    
        echo "âš ï¸ DAG timed out"
        exit 1

    # - name: 5.Stop EC2 instance
    #   if: always()
    #   run: |
    #     echo "ğŸ›‘ Stopping EC2 ${{ secrets.EC2_INSTANCE_ID }} ..."
    #     aws ec2 stop-instances --instance-ids ${{ secrets.EC2_INSTANCE_ID }}
    #     aws ec2 wait instance-stopped --instance-ids ${{ secrets.EC2_INSTANCE_ID }}
    #     echo "âœ… EC2 instance stopped"



          
  
