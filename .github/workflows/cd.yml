
name: CD

permissions:
  id-token: write
  contents: read

# on:
#   workflow_run:
#     workflows: ["CI"]   # 必须和 CI workflow 的 name 完全一致
#     types: [completed]
#     branches: [main]       # 只有 main 上的 CI 完成才触发

on:
  workflow_dispatch:
  push:
    branches: [main]

jobs:
  deploy:
    name: II.CD run_code
    # if: ${{ github.event.workflow_run.conclusion == 'success' }}  # 仅当 CI 成功
    runs-on: ubuntu-latest
    steps:
    - name: 0.Check out Git repository
      uses: actions/checkout@v4

    - name: 1.Configure aws credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region:            ${{ secrets.AWS_REGION }}



    - name: 2.Start EC2 instance
      run: |
        aws ec2 start-instances         --instance-ids ${{ secrets.EC2_INSTANCE_ID }}
        #确认连接成功
        aws ec2 wait instance-status-ok --instance-ids ${{ secrets.EC2_INSTANCE_ID }}
        echo "✅ EC2 instance is running"

    - name: 3.Setup Airflow via SSM
      run: |
        set -euo pipefail
    
        SCRIPT="/bin/bash -lc 'set -e; cd /home/ubuntu/world_pool; sudo systemctl start docker || true; sudo docker compose up -d; sudo docker compose ps'"
        jq -n --arg s "$SCRIPT" '{commands: [$s]}' > params.json
    
        CMD_ID=$(aws ssm send-command \
          --targets "Key=instanceIds,Values=${{ secrets.EC2_INSTANCE_ID }}" \
          --document-name "AWS-RunShellScript" \
          --comment "Start Airflow via SSM (compose v2)" \
          --region ${{ secrets.AWS_REGION }} \
          --parameters file://params.json \
          --query "Command.CommandId" --output text)
    
        echo "SSM Command ID: $CMD_ID"
    
        set +e
        aws ssm wait command-executed --command-id "$CMD_ID" --instance-id ${{ secrets.EC2_INSTANCE_ID }} --region ${{ secrets.AWS_REGION }}
        set -e
        #display log
        aws ssm get-command-invocation \
          --command-id "$CMD_ID" \
          --instance-id ${{ secrets.EC2_INSTANCE_ID }} \
          --region ${{ secrets.AWS_REGION }} \
          --query '{Status:Status, StdOut:StandardOutputContent, StdErr:StandardErrorContent}' \
          --output json
          
    - name: 4.Run Airflow dag
      env:
        AIRFLOW_HOST: ${{ secrets.AIRFLOW_HOST }}
        AIRFLOW_USER: ${{ secrets.AIRFLOW_USER }}
        AIRFLOW_PASS: ${{ secrets.AIRFLOW_PASS }}
        DAG_ID      : market_pv

  
      run: |
        curl -X POST "http://${AIRFLOW_HOST}:8080/api/v1/dags/${DAG_ID}/dagRuns" \
          -H "Content-Type: application/json" \
          -u "${AIRFLOW_USER}:${AIRFLOW_PASS}" \
          -d "{\"dag_run_id\": \"${DAG_RUN_ID}\"}"

        for i in {1..30}; do
          STATE=$(curl -s -u "${AIRFLOW_USER}:${AIRFLOW_PASS}" \
            "http://${AIRFLOW_HOST}:8080/api/v1/dags/${DAG_ID}/dagRuns/${DAG_RUN_ID}" | jq -r '.state')
    
          echo "[$i] DAG run state: $STATE"
          if [[ "$STATE" == "success" ]]; then
            echo "✅ DAG succeeded"
            exit 0
          elif [[ "$STATE" == "failed" ]]; then
            echo "❌ DAG failed"
            exit 1
          fi
          sleep 10
        done
    
        echo "⚠️ DAG timed out"
        exit 1

          
  
